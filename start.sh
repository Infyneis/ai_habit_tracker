#!/bin/bash

# âœ¨ HabitFlow - Startup Script
# ğŸš€ Starts all services needed for development

set -e

echo ""
echo "âœ¨ =================================="
echo "   HabitFlow - AI Habit Tracker"
echo "================================== âœ¨"
echo ""

# ğŸ³ Start PostgreSQL via Docker
echo "ğŸ³ Starting PostgreSQL database..."
docker compose down --remove-orphans 2>/dev/null || true
docker compose up -d postgres
echo "   âœ… PostgreSQL is running on port 5432"
echo ""

# ğŸ¦™ Check and start Ollama
echo "ğŸ¦™ Checking Ollama..."
if command -v ollama &> /dev/null; then
    echo "   âœ… Ollama is installed"

    # Check if Ollama is already running
    if pgrep -x "ollama" > /dev/null || curl -s http://localhost:11434/api/tags &> /dev/null; then
        echo "   âœ… Ollama is already running"
    else
        echo "   ğŸ”„ Starting Ollama server..."
        ollama serve &> /dev/null &
        sleep 2
        echo "   âœ… Ollama server started"
    fi

    # Check if llama3.2 model is available
    echo "   ğŸ” Checking for Llama 3.2 model..."
    if ollama list | grep -q "llama3.2"; then
        echo "   âœ… Llama 3.2 model is ready"
    else
        echo "   ğŸ“¥ Pulling Llama 3.2 model (this may take a few minutes)..."
        ollama pull llama3.2
        echo "   âœ… Llama 3.2 model downloaded"
    fi
else
    echo "   âš ï¸  Ollama not found"
    echo ""

    # Check if we're on macOS and have brew
    if [[ "$OSTYPE" == "darwin"* ]] && command -v brew &> /dev/null; then
        read -p "   Would you like to install Ollama via Homebrew? (y/n) " -n 1 -r
        echo ""
        if [[ $REPLY =~ ^[Yy]$ ]]; then
            echo "   ğŸ“¥ Installing Ollama..."
            brew install ollama
            echo "   âœ… Ollama installed"
            echo ""
            echo "   ğŸ”„ Starting Ollama server..."
            ollama serve &> /dev/null &
            sleep 2
            echo "   âœ… Ollama server started"
            echo ""
            echo "   ğŸ“¥ Pulling Llama 3.2 model (this may take a few minutes)..."
            ollama pull llama3.2
            echo "   âœ… Llama 3.2 model downloaded"
        else
            echo "   ğŸ’¡ Skipping Ollama - AI features will use fallback responses"
        fi
    else
        echo "   ğŸ’¡ Install Ollama manually from: https://ollama.ai"
        echo "   ğŸ’¡ AI features will use fallback responses for now"
    fi
fi
echo ""

# ğŸ“¦ Check if node_modules exists
if [ ! -d "node_modules" ]; then
    echo "ğŸ“¦ Installing dependencies..."
    pnpm install
    echo "   âœ… Dependencies installed"
    echo ""
fi

# ğŸ—„ï¸ Generate Prisma client if needed
if [ ! -d "src/generated/prisma" ]; then
    echo "ğŸ—„ï¸  Generating Prisma client..."
    pnpm prisma generate
    echo "   âœ… Prisma client generated"
    echo ""
fi

# ğŸ”„ Push database schema
echo "ğŸ—„ï¸  Syncing database schema..."
pnpm prisma db push
echo "   âœ… Database schema synced"
echo ""

# ğŸš€ Start the development server
echo "ğŸš€ Starting Next.js development server..."
echo ""
echo "ğŸ’œ =================================="
echo "   App running at: http://localhost:3000"
echo "   Database: localhost:5432"
echo "   Ollama API: localhost:11434"
echo "================================== ğŸ’œ"
echo ""

pnpm dev
